{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# character rnn workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "designed to give some hands on exposure to a chracter rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesystem and data downloading libraries\n",
    "import os # for filesystem operations\n",
    "import requests # for interacting with webpages to get data\n",
    "from zipfile import ZipFile # unzip in python to keep it all in one place\\\n",
    "import glob # easy file matching\n",
    "\n",
    "# numerical libraries\n",
    "import random\n",
    "import numpy as np # linear algebra library\n",
    "\n",
    "# text processing libraries\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import time\n",
    "\n",
    "# deep learning library\n",
    "import torch # mostly for tensors\n",
    "import torch.nn as nn # the Neural Networks module from torch. nn by convention\n",
    "\n",
    "# plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# premade\n",
    "url = 'https://download.pytorch.org/tutorial/data.zip'\n",
    "\n",
    "# data download and file managment\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "if not os.path.isfile('data/name_data.zip'):\n",
    "    r = requests.get(url) # download the data\n",
    "    with open('data/name_data.zip', 'wb') as f:\n",
    "        f.write(r.content) # save the data to a file\n",
    "\n",
    "# extract the data\n",
    "with ZipFile('data/name_data.zip', 'r') as data_zip:\n",
    "   # Extract all the contents of the data zip file in to the data directory\n",
    "   data_zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the folders and the file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the data directory contents\n",
    "# print out some of the file contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all language files as a list\n",
    "fnames = []\n",
    "fnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string cleaner helper functions\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def clean_names(name):\n",
    "    return unicode_to_ascii(name.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables of the total character set\n",
    "all_letters = \"\"\n",
    "n_letters = len(all_letters)\n",
    "n_letters, all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the language files into a list of languages and a {language:names} dict\n",
    "all_languages = [] # list of language names\n",
    "language_names = {} # dict of key = language, value = list of all names in that language\n",
    "\n",
    "n_languages = len(all_languages)\n",
    "print(n_languages, all_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data as tensors (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# livecode helper functions\n",
    "def character_to_tensor(c):\n",
    "    return t\n",
    "\n",
    "def word_to_tensor(word):\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out some letter/word to tensor examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def random_choice(l):\n",
    "    \"\"\"random selection from list\"\"\"\n",
    "    item = l[random.randint(0, len(l)-1)]\n",
    "    return item \n",
    "    \n",
    "def random_language_name(language=None):\n",
    "    \"\"\"returns all the information for a random language-name pair\n",
    "    \n",
    "    args:\n",
    "        language = if None, select a random language\n",
    "    \"\"\"\n",
    "    if language==None:\n",
    "        language = random_choice(all_languages)\n",
    "\n",
    "    name = random_choice(language_names[language])\n",
    "\n",
    "    language_index = all_languages.index(language)\n",
    "    language_tensor = torch.tensor(language_index)\n",
    "\n",
    "    name_tensor = word_to_tensor(name)\n",
    "    \n",
    "    return language, name, language_tensor, name_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore some random names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the specific RNN structure that we want to be building:\n",
    "\n",
    "![network diagram](network_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livecode\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"This dictates the structure and size of the network\"\"\"\n",
    "    def __init__(self, data_size, hidden_size, output_size):\n",
    "        \"\"\"Sets up class attributes (mostly data dimensions) and network layers\"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "    \n",
    "    def forward(self, x, last_hidden):\n",
    "        \"\"\"Describes how data moves through the RNN layers\"\"\"\n",
    "        return output_probabilities, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a RNN\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a character through it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making sense of model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_from_output(output):\n",
    "    \"\"\"takes output probability vector and returns top language\"\"\"\n",
    "\n",
    "    top_value, top_index = output.topk(1)\n",
    "    index = top_index[0].item()\n",
    "    probability = top_value[0].item()\n",
    "    language = all_languages[index]\n",
    "    return language, index, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore some output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and update model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # negative log likelihood loss. Convention\n",
    "lr = 0.005 # totally arbitrary starter learning rate\n",
    "\n",
    "def predict(rnn, name_t):\n",
    "    \"\"\"pass each character in an input name tensor through the network\"\"\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def train_step(lang_t, name_t):\n",
    "    \"\"\"predict language, compare with target, and update model parameters \"\"\"\n",
    "    \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out a train step on a random name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(start):\n",
    "    \"\"\"little helper for pretty timestamping\"\"\"\n",
    "    now = time.time()\n",
    "    dt = now - start\n",
    "    mins = int(dt/60)\n",
    "    return f'{mins:>02}:{dt - mins*60:>05.2f}(m:s)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, n_iters):\n",
    "    \"\"\"loop the train_step and view progress\"\"\"\n",
    "    \n",
    "    return losses, average_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training run and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run some training, and look at the losses/outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of success: Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# live code \n",
    "def language_confusion(rnn, language, n_samples = 100):\n",
    "    \"\"\"evaluate how often the model predicts names from a language correctly\"\"\"\n",
    "    \n",
    "    return norm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = language_confusion(rnn, \"Polish\")\n",
    "preds, sum([p for p in preds.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_total_confusion(rnn,samples_per_language=100):\n",
    "    \"\"\"Calculates confusion array for all languages\"\"\"\n",
    "    confusion_list = []\n",
    "    \n",
    "    return np.concatenate(confusion_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(confusion):\n",
    "    \"\"\"displays a nxn confusion numpy array\"\"\"\n",
    "    # Set up plot\n",
    "    fig = plt.figure(facecolor='white',figsize=(5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # add the color scale\n",
    "    cax = ax.matshow(confusion)\n",
    "    cbar = fig.colorbar(cax)\n",
    "    \n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + all_languages, rotation=90)\n",
    "    ax.set_yticklabels([''] + all_languages)\n",
    "\n",
    "    # Force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # labeling\n",
    "    ax.set_xlabel(\"predicted languag\")\n",
    "    ax.set_ylabel(\"target languag\")\n",
    "    cbar.ax.set_ylabel('predicted fraction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = evaluate_total_confusion(samples_per_language = 100)\n",
    "plot_confusion(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
